#!/bin/bash
# Orchestrator Watchdog v3.0
# Monitors the main orchestrator and restarts it if it dies
# Now with configuration file support, token limits, and enhanced monitoring
# 
# Usage:
#   ./orchestrator-watchdog.sh           # Run in foreground
#   ./orchestrator-watchdog.sh start     # Start in background
#   ./orchestrator-watchdog.sh stop      # Stop watchdog and orchestrator
#   ./orchestrator-watchdog.sh status    # Check status
#   ./orchestrator-watchdog.sh restart   # Restart orchestrator
#   ./orchestrator-watchdog.sh config    # Show current configuration
#   ./orchestrator-watchdog.sh init-config # Generate default config file
#
# Configuration: Create .watchdog.conf in /app/workspace/memory/ or use defaults
#
# Run in background: nohup ./orchestrator-watchdog.sh start &

set -euo pipefail

cd /app/workspace

# ==============================================================================
# DEFAULT CONFIGURATION (can be overridden by config file)
# ==============================================================================

# File paths
PIDFILE="memory/.orchestrator.pid"
WATCHDOG_PIDFILE="memory/.watchdog.pid"
LOGFILE="logs/watchdog.log"
STARTUP_LOGFILE="logs/watchdog-startup.log"
STATUS_FILE="memory/.watchdog-status.json"
RESTART_COUNT_FILE="memory/.restart-count.json"
CONFIG_FILE="memory/.watchdog.conf"
TOKEN_TRACKING_FILE="memory/.token-usage.json"
RATE_LIMIT_FILE="memory/.rate-limit-status.json"

# Timing configuration
CHECK_INTERVAL=30           # seconds between health checks
STARTUP_DELAY=5             # seconds to wait after starting orchestrator
HEALTH_CHECK_TIMEOUT=10     # seconds to wait for health check response
GRACEFUL_SHUTDOWN_TIMEOUT=10 # seconds to wait for graceful shutdown

# Restart limits
MAX_RESTARTS=50             # max restarts per hour (higher since sessions are short)
RESTART_BACKOFF_ENABLED=false # DISABLED - short orchestration sessions are desired
RESTART_BACKOFF_BASE=5      # minimal base backoff time in seconds
RESTART_BACKOFF_MAX=30      # max backoff time in seconds

# Token limits (per session)
TOKEN_LIMIT_ENABLED=true    # enable token limit enforcement
TOKEN_LIMIT_INPUT=100000    # max input tokens per session
TOKEN_LIMIT_OUTPUT=50000    # max output tokens per session
TOKEN_LIMIT_TOTAL=150000    # max total tokens per session (0 = unlimited)
TOKEN_CHECK_INTERVAL=60     # how often to check token usage (seconds)

# Session configuration
SESSION_TIMEOUT=0           # max session duration in seconds (0 = unlimited)
IDLE_TIMEOUT=0              # restart if idle for this many seconds (0 = disabled)

# Model configuration
# Priority: environment variable > config file > default
MODEL="${OPENCODE_MODEL:-anthropic/claude-opus-4-5}"   # default model to use
MODEL_FALLBACK="${OPENCODE_MODEL_FALLBACK:-anthropic/claude-sonnet}"  # fallback model
RATE_LIMIT_COOLDOWN="${OPENCODE_RATE_LIMIT_COOLDOWN:-300}"  # seconds to wait when rate limited

# Memory limits
MEMORY_LIMIT_MB=0           # max memory usage in MB (0 = unlimited)
MEMORY_CHECK_INTERVAL=60    # how often to check memory (seconds)

# Log rotation
LOG_ROTATION_ENABLED=true   # enable log rotation
LOG_MAX_SIZE_MB=50          # max log file size before rotation
LOG_MAX_FILES=5             # number of rotated files to keep

# Notification (placeholder for future webhook support)
NOTIFY_ON_RESTART=false
NOTIFY_WEBHOOK_URL=""

# ==============================================================================
# LOAD CONFIGURATION FILE
# ==============================================================================

load_config() {
    if [[ -f "$CONFIG_FILE" ]]; then
        # Source the config file (shell format: KEY=value)
        # shellcheck disable=SC1090
        source "$CONFIG_FILE"
        # Note: log function may not be defined yet at startup
        # Log will be written later when function is available
    fi
}

# Generate default config file
generate_config() {
    cat > "$CONFIG_FILE" << 'CONFIGEOF'
# Orchestrator Watchdog Configuration
# Generated by watchdog v3.0
# Edit this file to customize watchdog behavior

# ==============================================================================
# TIMING CONFIGURATION
# ==============================================================================
CHECK_INTERVAL=30           # seconds between health checks
STARTUP_DELAY=5             # seconds to wait after starting orchestrator
HEALTH_CHECK_TIMEOUT=10     # seconds to wait for health check response
GRACEFUL_SHUTDOWN_TIMEOUT=10 # seconds to wait for graceful shutdown

# ==============================================================================
# RESTART LIMITS
# ==============================================================================
MAX_RESTARTS=50             # max restarts per hour (higher since sessions are short)
RESTART_BACKOFF_ENABLED=false # DISABLED - we want short orchestration sessions
RESTART_BACKOFF_BASE=5      # minimal backoff time in seconds
RESTART_BACKOFF_MAX=30      # max backoff time in seconds

# ==============================================================================
# TOKEN LIMITS (Per Session)
# ==============================================================================
# These limits help control costs and prevent runaway sessions
TOKEN_LIMIT_ENABLED=true    # enable token limit enforcement
TOKEN_LIMIT_INPUT=100000    # max input tokens per session
TOKEN_LIMIT_OUTPUT=50000    # max output tokens per session
TOKEN_LIMIT_TOTAL=150000    # max total tokens per session (0 = unlimited)
TOKEN_CHECK_INTERVAL=60     # how often to check token usage (seconds)

# ==============================================================================
# SESSION CONFIGURATION
# ==============================================================================
SESSION_TIMEOUT=0           # max session duration in seconds (0 = unlimited)
IDLE_TIMEOUT=0              # restart if idle for this many seconds (0 = disabled)

# ==============================================================================
# MODEL CONFIGURATION
# ==============================================================================
# Use environment variables OPENCODE_MODEL and OPENCODE_MODEL_FALLBACK to override
MODEL="anthropic/claude-opus-4-5"   # primary model to use
MODEL_FALLBACK="anthropic/claude-sonnet"  # fallback model if primary fails
RATE_LIMIT_COOLDOWN=300      # seconds to wait when rate limited

# ==============================================================================
# MEMORY LIMITS
# ==============================================================================
MEMORY_LIMIT_MB=0           # max memory usage in MB (0 = unlimited)
MEMORY_CHECK_INTERVAL=60    # how often to check memory (seconds)

# ==============================================================================
# LOG ROTATION
# ==============================================================================
LOG_ROTATION_ENABLED=true   # enable log rotation
LOG_MAX_SIZE_MB=50          # max log file size before rotation
LOG_MAX_FILES=5             # number of rotated files to keep

# ==============================================================================
# NOTIFICATIONS (Future Feature)
# ==============================================================================
NOTIFY_ON_RESTART=false
NOTIFY_WEBHOOK_URL=""
CONFIGEOF

    echo "Configuration file created: $CONFIG_FILE"
}

# ==============================================================================
# INITIALIZATION
# ==============================================================================

# Ensure directories exist
mkdir -p logs memory

# Load config after defining defaults
load_config

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# ==============================================================================
# LOGGING FUNCTIONS
# ==============================================================================

log() {
    local level="${2:-INFO}"
    local timestamp=$(date -Iseconds)
    local msg="[$timestamp] [$level] $1"
    
    # Rotate logs if needed
    maybe_rotate_logs
    
    echo "$msg" >> "$LOGFILE"
    
    # Only print to stdout if not running in background
    if [[ -t 1 ]]; then
        case $level in
            ERROR) echo -e "${RED}[Watchdog] $1${NC}" ;;
            WARN)  echo -e "${YELLOW}[Watchdog] $1${NC}" ;;
            OK)    echo -e "${GREEN}[Watchdog] $1${NC}" ;;
            DEBUG) echo -e "${CYAN}[Watchdog] $1${NC}" ;;
            *)     echo -e "${BLUE}[Watchdog]${NC} $1" ;;
        esac
    fi
}

# ==============================================================================
# LOG ROTATION
# ==============================================================================

maybe_rotate_logs() {
    if [[ "$LOG_ROTATION_ENABLED" != "true" ]]; then
        return
    fi
    
    if [[ ! -f "$LOGFILE" ]]; then
        return
    fi
    
    local size_kb=$(du -k "$LOGFILE" 2>/dev/null | cut -f1 || echo "0")
    local max_kb=$((LOG_MAX_SIZE_MB * 1024))
    
    if [[ $size_kb -gt $max_kb ]]; then
        # Rotate existing files
        for i in $(seq $((LOG_MAX_FILES - 1)) -1 1); do
            if [[ -f "${LOGFILE}.$i" ]]; then
                mv "${LOGFILE}.$i" "${LOGFILE}.$((i + 1))"
            fi
        done
        
        # Rotate current log
        mv "$LOGFILE" "${LOGFILE}.1"
        
        # Remove oldest if over limit
        if [[ -f "${LOGFILE}.$((LOG_MAX_FILES + 1))" ]]; then
            rm -f "${LOGFILE}.$((LOG_MAX_FILES + 1))"
        fi
        
        echo "[$(date -Iseconds)] [INFO] Log rotated" >> "$LOGFILE"
    fi
}

# ==============================================================================
# TOKEN TRACKING
# ==============================================================================

init_token_tracking() {
    cat > "$TOKEN_TRACKING_FILE" << EOF
{
    "session_start": "$(date -Iseconds)",
    "input_tokens": 0,
    "output_tokens": 0,
    "total_tokens": 0,
    "last_updated": "$(date -Iseconds)",
    "limit_reached": false
}
EOF
}

get_token_usage() {
    if [[ ! -f "$TOKEN_TRACKING_FILE" ]]; then
        echo "0"
        return
    fi
    jq -r '.total_tokens // 0' "$TOKEN_TRACKING_FILE" 2>/dev/null || echo "0"
}

get_session_tokens_from_opencode() {
    # Try to get token usage from OpenCode sessions
    # This reads from the opencode-sessions.json if available
    local sessions_file="memory/opencode-sessions.json"
    
    if [[ -f "$sessions_file" ]]; then
        # Get the most recent active session's token count
        local tokens
        tokens=$(jq -r '
            .sessions // [] |
            sort_by(.started_at) |
            reverse |
            .[0] |
            .token_count // 0
        ' "$sessions_file" 2>/dev/null || echo "0")
        echo "$tokens"
    else
        echo "0"
    fi
}

update_token_usage() {
    local input="${1:-0}"
    local output="${2:-0}"
    
    local current_input=0
    local current_output=0
    
    if [[ -f "$TOKEN_TRACKING_FILE" ]]; then
        current_input=$(jq -r '.input_tokens // 0' "$TOKEN_TRACKING_FILE" 2>/dev/null || echo "0")
        current_output=$(jq -r '.output_tokens // 0' "$TOKEN_TRACKING_FILE" 2>/dev/null || echo "0")
    fi
    
    local new_input=$((current_input + input))
    local new_output=$((current_output + output))
    local new_total=$((new_input + new_output))
    
    local limit_reached="false"
    if [[ "$TOKEN_LIMIT_ENABLED" == "true" ]]; then
        if [[ $TOKEN_LIMIT_TOTAL -gt 0 && $new_total -ge $TOKEN_LIMIT_TOTAL ]]; then
            limit_reached="true"
        elif [[ $TOKEN_LIMIT_INPUT -gt 0 && $new_input -ge $TOKEN_LIMIT_INPUT ]]; then
            limit_reached="true"
        elif [[ $TOKEN_LIMIT_OUTPUT -gt 0 && $new_output -ge $TOKEN_LIMIT_OUTPUT ]]; then
            limit_reached="true"
        fi
    fi
    
    cat > "$TOKEN_TRACKING_FILE" << EOF
{
    "session_start": "$(jq -r '.session_start // "'"$(date -Iseconds)"'"' "$TOKEN_TRACKING_FILE" 2>/dev/null || date -Iseconds)",
    "input_tokens": $new_input,
    "output_tokens": $new_output,
    "total_tokens": $new_total,
    "last_updated": "$(date -Iseconds)",
    "limit_reached": $limit_reached,
    "limits": {
        "input": $TOKEN_LIMIT_INPUT,
        "output": $TOKEN_LIMIT_OUTPUT,
        "total": $TOKEN_LIMIT_TOTAL
    }
}
EOF
    
    echo "$limit_reached"
}

check_token_limits() {
    if [[ "$TOKEN_LIMIT_ENABLED" != "true" ]]; then
        return 0
    fi
    
    # Get current token usage from OpenCode
    local current_tokens
    current_tokens=$(get_session_tokens_from_opencode)
    
    # Update tracking (rough estimate - split 60/40 input/output)
    local input_est=$((current_tokens * 60 / 100))
    local output_est=$((current_tokens * 40 / 100))
    
    local limit_reached
    limit_reached=$(update_token_usage "$input_est" "$output_est")
    
    if [[ "$limit_reached" == "true" ]]; then
        log "Token limit reached! Current: $current_tokens, Limit: $TOKEN_LIMIT_TOTAL" "WARN"
        return 1
    fi
    
    return 0
}

# ==============================================================================
# RATE LIMIT DETECTION
# ==============================================================================

# Check if we're currently rate limited by checking recent logs
check_rate_limit_status() {
    # Check the startup log for recent 429 errors
    if [[ -f "$STARTUP_LOGFILE" ]]; then
        local recent_429s
        recent_429s=$(tail -50 "$STARTUP_LOGFILE" 2>/dev/null | grep -c "429 error\|usage_limit_reached\|rate limit" 2>/dev/null || echo "0")
        recent_429s="${recent_429s//[^0-9]/}"  # Remove non-numeric chars
        recent_429s="${recent_429s:-0}"  # Default to 0 if empty
        
        if [[ "$recent_429s" -gt 3 ]]; then
            # Extract resets_in_seconds from last 429 error if available
            local reset_time
            reset_time=$(tail -20 "$STARTUP_LOGFILE" 2>/dev/null | grep -o '"resets_in_seconds":[0-9]*' | tail -1 | cut -d':' -f2 || echo "0")
            reset_time="${reset_time//[^0-9]/}"  # Remove non-numeric chars
            reset_time="${reset_time:-0}"  # Default to 0 if empty
            
            if [[ "$reset_time" -gt 0 ]]; then
                log "Rate limit detected! API resets in ${reset_time}s" "WARN"
                # Store rate limit status
                cat > "$RATE_LIMIT_FILE" << EOF
{
    "rate_limited": true,
    "detected_at": "$(date -Iseconds)",
    "resets_in_seconds": $reset_time,
    "retry_after": "$(date -d "+${reset_time} seconds" -Iseconds 2>/dev/null || date -Iseconds)"
}
EOF
                return 1  # Rate limited
            fi
        fi
    fi
    
    # Check stored rate limit file
    if [[ -f "$RATE_LIMIT_FILE" ]]; then
        local stored_retry
        stored_retry=$(jq -r '.retry_after // ""' "$RATE_LIMIT_FILE" 2>/dev/null || echo "")
        if [[ -n "$stored_retry" ]]; then
            local retry_epoch
            retry_epoch=$(date -d "$stored_retry" +%s 2>/dev/null || echo "0")
            local now_epoch
            now_epoch=$(date +%s)
            
            if [[ $retry_epoch -gt $now_epoch ]]; then
                local wait_secs=$((retry_epoch - now_epoch))
                log "Still rate limited. Wait ${wait_secs}s more." "WARN"
                return 1
            else
                # Rate limit expired, clear it
                rm -f "$RATE_LIMIT_FILE"
            fi
        fi
    fi
    
    return 0  # Not rate limited
}

# Wait for rate limit to clear if needed
wait_for_rate_limit() {
    if ! check_rate_limit_status; then
        local wait_time=$RATE_LIMIT_COOLDOWN
        
        # Try to get actual wait time from status file
        if [[ -f "$RATE_LIMIT_FILE" ]]; then
            local stored_retry
            stored_retry=$(jq -r '.retry_after // ""' "$RATE_LIMIT_FILE" 2>/dev/null || echo "")
            if [[ -n "$stored_retry" ]]; then
                local retry_epoch
                retry_epoch=$(date -d "$stored_retry" +%s 2>/dev/null || echo "0")
                local now_epoch
                now_epoch=$(date +%s)
                
                if [[ $retry_epoch -gt $now_epoch ]]; then
                    wait_time=$((retry_epoch - now_epoch))
                    # Cap at reasonable maximum
                    if [[ $wait_time -gt 1800 ]]; then
                        wait_time=1800
                    fi
                fi
            fi
        fi
        
        log "Waiting ${wait_time}s for rate limit to clear..." "WARN"
        update_status "rate_limited" "Waiting for rate limit cooldown" 0
        sleep "$wait_time"
        rm -f "$RATE_LIMIT_FILE"
        log "Rate limit cooldown complete" "INFO"
    fi
}

# ==============================================================================
# MEMORY MONITORING
# ==============================================================================

check_memory_usage() {
    if [[ $MEMORY_LIMIT_MB -eq 0 ]]; then
        return 0
    fi
    
    if [[ ! -f "$PIDFILE" ]]; then
        return 0
    fi
    
    local pid
    pid=$(cat "$PIDFILE" 2>/dev/null || echo "0")
    
    if [[ "$pid" == "0" ]] || ! ps -p "$pid" > /dev/null 2>&1; then
        return 0
    fi
    
    # Get memory usage in KB, then convert to MB
    local mem_kb
    mem_kb=$(ps -p "$pid" -o rss= 2>/dev/null | tr -d ' ' || echo "0")
    local mem_mb=$((mem_kb / 1024))
    
    if [[ $mem_mb -gt $MEMORY_LIMIT_MB ]]; then
        log "Memory limit exceeded! Current: ${mem_mb}MB, Limit: ${MEMORY_LIMIT_MB}MB" "WARN"
        return 1
    fi
    
    return 0
}

# ==============================================================================
# SESSION MANAGEMENT
# ==============================================================================

# Get session count from state.json
get_session_count() {
    if [[ -f "memory/state.json" ]]; then
        jq -r '.session_count // 0' memory/state.json 2>/dev/null || echo "0"
    else
        echo "0"
    fi
}

# Track session start time
SESSION_START_TIME=""

record_session_start() {
    SESSION_START_TIME=$(date +%s)
}

check_session_timeout() {
    if [[ $SESSION_TIMEOUT -eq 0 ]] || [[ -z "$SESSION_START_TIME" ]]; then
        return 0
    fi
    
    local current_time
    current_time=$(date +%s)
    local elapsed=$((current_time - SESSION_START_TIME))
    
    if [[ $elapsed -gt $SESSION_TIMEOUT ]]; then
        log "Session timeout reached (${elapsed}s > ${SESSION_TIMEOUT}s)" "WARN"
        return 1
    fi
    
    return 0
}

# ==============================================================================
# STATUS MANAGEMENT
# ==============================================================================

# Update watchdog status file
update_status() {
    local status="$1"
    local details="${2:-}"
    local pid="${3:-0}"
    
    local token_usage
    token_usage=$(get_token_usage)
    
    cat > "$STATUS_FILE" << EOF
{
    "status": "$status",
    "last_check": "$(date -Iseconds)",
    "orchestrator_pid": $pid,
    "details": "$details",
    "watchdog_pid": $$,
    "restarts_this_hour": $(get_restart_count),
    "token_usage": $token_usage,
    "token_limit": $TOKEN_LIMIT_TOTAL,
    "model": "$MODEL",
    "config_loaded": $([ -f "$CONFIG_FILE" ] && echo "true" || echo "false"),
    "version": "3.0"
}
EOF
}

# ==============================================================================
# RESTART MANAGEMENT
# ==============================================================================

# Track restart count to prevent restart loops
get_restart_count() {
    if [[ -f "$RESTART_COUNT_FILE" ]]; then
        local hour=$(date +%H)
        local stored_hour=$(jq -r '.hour // ""' "$RESTART_COUNT_FILE" 2>/dev/null)
        if [[ "$stored_hour" == "$hour" ]]; then
            jq -r '.count // 0' "$RESTART_COUNT_FILE" 2>/dev/null
            return
        fi
    fi
    echo "0"
}

increment_restart_count() {
    local hour=$(date +%H)
    local current_count=$(get_restart_count)
    local new_count=$((current_count + 1))
    
    # Reset if new hour
    local stored_hour=""
    if [[ -f "$RESTART_COUNT_FILE" ]]; then
        stored_hour=$(jq -r '.hour // ""' "$RESTART_COUNT_FILE" 2>/dev/null)
    fi
    
    if [[ "$stored_hour" != "$hour" ]]; then
        new_count=1
    fi
    
    cat > "$RESTART_COUNT_FILE" << EOF
{
    "hour": "$hour",
    "count": $new_count,
    "last_restart": "$(date -Iseconds)"
}
EOF
    echo "$new_count"
}

# Calculate backoff time with exponential increase
calculate_backoff() {
    local restart_count="$1"
    
    if [[ "$RESTART_BACKOFF_ENABLED" != "true" ]]; then
        echo "0"
        return
    fi
    
    # Exponential backoff: base * 2^(count-1), capped at max
    local backoff=$((RESTART_BACKOFF_BASE * (1 << (restart_count - 1))))
    
    if [[ $backoff -gt $RESTART_BACKOFF_MAX ]]; then
        backoff=$RESTART_BACKOFF_MAX
    fi
    
    echo "$backoff"
}

# ==============================================================================
# USER MESSAGES AND TASKS
# ==============================================================================

# Get unread user messages from the queue
get_unread_user_messages() {
    local user_msg_file="memory/user-messages.jsonl"
    
    if [[ ! -f "$user_msg_file" ]]; then
        echo ""
        return
    fi
    
    # Get unread messages (read=false), format them nicely
    local messages=""
    while IFS= read -r line; do
        local is_read=$(echo "$line" | jq -r '.read // false')
        if [[ "$is_read" == "false" ]]; then
            local id=$(echo "$line" | jq -r '.id')
            local from=$(echo "$line" | jq -r '.from // "user"')
            local msg=$(echo "$line" | jq -r '.message')
            local ts=$(echo "$line" | jq -r '.timestamp')
            local priority=$(echo "$line" | jq -r '.priority // "normal"')
            
            if [[ -n "$messages" ]]; then
                messages="$messages\n"
            fi
            messages="${messages}- [$priority] [$ts] $from: $msg (id: $id)"
        fi
    done < "$user_msg_file"
    
    echo -e "$messages"
}

# Get pending tasks summary
get_pending_tasks() {
    local tasks_file="memory/tasks.json"
    
    if [[ ! -f "$tasks_file" ]]; then
        echo "No tasks file found"
        return
    fi
    
    # Get pending and in_progress tasks
    jq -r '
        .tasks // [] | 
        map(select(.status == "pending" or .status == "in_progress")) |
        if length == 0 then "No pending tasks" 
        else 
            map("- [\(.status)] \(.title // .description) (priority: \(.priority // "normal"))") | 
            join("\n")
        end
    ' "$tasks_file" 2>/dev/null || echo "Error reading tasks"
}

# ==============================================================================
# PROMPT GENERATION
# ==============================================================================

# Generate orchestrator prompt dynamically from queue
generate_prompt() {
    # Try to use the TypeScript prompt generator first
    if command -v bun &> /dev/null && [[ -f "tools/generate-orchestrator-prompt.ts" ]]; then
        local ts_prompt
        ts_prompt=$(bun tools/generate-orchestrator-prompt.ts 2>/dev/null || true)
        if [[ -n "$ts_prompt" ]] && [[ "$ts_prompt" != "" ]]; then
            echo "$ts_prompt"
            return 0
        fi
    fi
    
    # Dynamic prompt based on user messages queue
    local session_count=$(get_session_count)
    local unread_messages=$(get_unread_user_messages)
    local pending_tasks=$(get_pending_tasks)
    local has_messages="false"
    
    if [[ -n "$unread_messages" ]] && [[ "$unread_messages" != "" ]]; then
        has_messages="true"
    fi
    
    # Use quoted heredoc to prevent variable expansion issues and allow literal backticks
    cat << 'PROMPT_EOF'
<role>
You are the ORCHESTRATOR - the persistent coordinator of a multi-agent AI system.
You were auto-restarted by watchdog v3.0. Your job: delegate work, monitor progress, maintain the system.
</role>

<critical_first_actions>
Execute IMMEDIATELY in this order:
1. agent_set_handoff(enabled=false) - PREVENTS YOU FROM STOPPING
2. agent_register(role='orchestrator') - Register as coordinator
3. user_messages_read() - CHECK FOR USER REQUESTS (highest priority!)
4. task_list(status='pending') - See what needs workers
</critical_first_actions>

<core_principle>
DELEGATE, DON'T IMPLEMENT. Your job is to:
- Coordinate work, not do it yourself
- Spawn worker agents for actual tasks
- Monitor progress and handle completions
- Keep sessions focused and efficient
</core_principle>

<spawning_workers>
Spawn workers using bash (NON-BLOCKING):

```bash
nohup opencode run '<worker_prompt>' > /dev/null 2>&1 &
```

Worker prompt template:
```
You are a WORKER agent. 
1. agent_register(role='worker')
2. Task: [SPECIFIC TASK DESCRIPTION]
3. When complete: agent_send(type='task_complete', payload={task_id, summary})
4. Then exit normally (handoff enabled)
```

IMPORTANT: Always use nohup ... & for fire-and-forget spawning.
</spawning_workers>

<context>
PROMPT_EOF
    
    # Output context variables (outside quoted heredoc)
    echo "- Session count: $session_count"
    echo "- Model: $MODEL"
    echo "- Token limit: $TOKEN_LIMIT_TOTAL"
    echo ""

    # Add unread messages section if any
    if [[ "$has_messages" == "true" ]]; then
        cat << 'MSG_EOF'
## UNREAD USER MESSAGES (PRIORITY - Address these first!):
MSG_EOF
        echo "$unread_messages"
        echo ""
        cat << 'MSG_EOF'
After processing each message, use user_messages_mark_read to mark it as handled.

MSG_EOF
    else
        cat << 'MSG_EOF'
## USER MESSAGES:
No unread messages. Use user_messages_read to check for new requests periodically.

MSG_EOF
    fi

    # Add pending tasks
    cat << 'TASK_EOF'
</context>

<pending_tasks>
TASK_EOF
    echo "$pending_tasks"
    echo ""
    cat << 'TASK_EOF'
</pending_tasks>

<workflow>
1. USER MESSAGES FIRST: If unread messages exist, spawn workers to handle them
2. PENDING TASKS: Spawn workers for high-priority pending tasks
3. MONITOR: Check agent_status() and agent_messages() for completions
4. IDLE: If nothing to do, exit gracefully (watchdog restarts you)
</workflow>

<available_tools>
Agent: agent_set_handoff(enabled), agent_register(role), agent_status(), agent_send(type, payload), agent_messages()
Memory: memory_status(), memory_search(query), memory_update(status/achievement)
Tasks: task_list(status), task_create(title, priority), task_update(task_id, status), task_claim(task_id), task_next()
Quality: quality_assess(task_id, score), quality_report()
User: user_messages_read(), user_messages_mark_read(id)
Git: git_status(), git_diff(), git_log(), git_commit(message)
Recovery: checkpoint_save(description), checkpoint_load(id), recovery_status()
</available_tools>

<constraints>
- You are the COORDINATOR, not a worker - DELEGATE everything
- Keep sessions focused (under 10 minutes ideally)
- Spawn workers for actual work, then monitor
- The watchdog restarts you automatically if you exit
</constraints>

BEGIN: Execute critical_first_actions NOW, then follow the workflow.
TASK_EOF
}

# ==============================================================================
# ORCHESTRATOR LIFECYCLE
# ==============================================================================

# Start the orchestrator
start_orchestrator() {
    local restart_count=$(increment_restart_count)
    
    if [[ $restart_count -gt $MAX_RESTARTS ]]; then
        log "Too many restarts this hour ($restart_count/$MAX_RESTARTS). Waiting..." "ERROR"
        update_status "restart_limit" "Exceeded max restarts" 0
        
        local backoff
        backoff=$(calculate_backoff "$restart_count")
        if [[ $backoff -gt 0 ]]; then
            log "Backing off for ${backoff}s due to restart limit" "WARN"
            sleep "$backoff"
        else
            sleep 300  # Default 5 minutes
        fi
        return 1
    fi
    
    # Check for rate limits before starting
    if ! check_rate_limit_status; then
        wait_for_rate_limit
    fi
    
    # Calculate and apply backoff if enabled
    if [[ $restart_count -gt 1 && "$RESTART_BACKOFF_ENABLED" == "true" ]]; then
        local backoff
        backoff=$(calculate_backoff "$restart_count")
        if [[ $backoff -gt 0 ]]; then
            log "Applying restart backoff: ${backoff}s (restart #$restart_count)" "INFO"
            sleep "$backoff"
        fi
    fi
    
    log "Starting orchestrator agent (restart #$restart_count this hour)..."
    
    # Initialize token tracking for new session
    init_token_tracking
    
    # Generate prompt
    local prompt
    prompt=$(generate_prompt)
    
    # Log startup command
    echo "[$( date -Iseconds)] Starting with prompt:" >> "$STARTUP_LOGFILE"
    echo "$prompt" >> "$STARTUP_LOGFILE"
    echo "---" >> "$STARTUP_LOGFILE"
    
    # Determine which model to use
    local use_model="$MODEL"
    local use_fallback="false"
    
    # Use fallback ONLY if rate limited (restarts are normal behavior)
    if [[ -n "$MODEL_FALLBACK" ]]; then
        # Check if we recently had rate limits
        if [[ -f "$RATE_LIMIT_FILE" ]]; then
            use_fallback="true"
            log "Using fallback model due to recent rate limits" "WARN"
        fi
    fi
    
    if [[ "$use_fallback" == "true" && -n "$MODEL_FALLBACK" ]]; then
        use_model="$MODEL_FALLBACK"
    fi
    
    # Start opencode in background
    opencode run --model "$use_model" "$prompt" >> "$STARTUP_LOGFILE" 2>&1 &
    
    local pid=$!
    echo $pid > "$PIDFILE"
    
    # Record session start for timeout tracking
    record_session_start
    
    log "Orchestrator started with PID: $pid (model: $use_model)" "OK"
    update_status "starting" "Orchestrator starting" $pid
    
    # Wait for startup
    sleep $STARTUP_DELAY
    
    # Verify it's still running
    if is_orchestrator_running; then
        log "Orchestrator confirmed running" "OK"
        update_status "running" "Orchestrator healthy" $pid
        return 0
    else
        log "Orchestrator failed to start!" "ERROR"
        update_status "failed" "Startup failed" 0
        return 1
    fi
}

# Check if orchestrator is running
is_orchestrator_running() {
    if [[ -f "$PIDFILE" ]]; then
        local pid=$(cat "$PIDFILE")
        
        # Check if process exists
        if ps -p "$pid" > /dev/null 2>&1; then
            # Verify it's an opencode process (check command line)
            local cmdline
            cmdline=$(ps -p "$pid" -o args= 2>/dev/null || true)
            
            if [[ "$cmdline" == *"opencode"* ]]; then
                return 0  # Running
            fi
        fi
    fi
    return 1  # Not running
}

# Stop the orchestrator
stop_orchestrator() {
    log "Stopping orchestrator..."
    
    if [[ -f "$PIDFILE" ]]; then
        local pid=$(cat "$PIDFILE")
        
        if ps -p "$pid" > /dev/null 2>&1; then
            # Try graceful shutdown first
            kill -TERM "$pid" 2>/dev/null || true
            
            # Wait for graceful shutdown
            local count=0
            while ps -p "$pid" > /dev/null 2>&1 && [[ $count -lt $GRACEFUL_SHUTDOWN_TIMEOUT ]]; do
                sleep 1
                count=$((count + 1))
            done
            
            # Force kill if still running
            if ps -p "$pid" > /dev/null 2>&1; then
                log "Force killing orchestrator..." "WARN"
                kill -9 "$pid" 2>/dev/null || true
            fi
        fi
        
        rm -f "$PIDFILE"
    fi
    
    log "Orchestrator stopped" "OK"
    update_status "stopped" "Orchestrator stopped" 0
}

# Stop the watchdog itself
stop_watchdog() {
    log "Stopping watchdog..."
    
    # Stop orchestrator first
    stop_orchestrator
    
    # Remove watchdog PID file
    rm -f "$WATCHDOG_PIDFILE"
    
    log "Watchdog stopped" "OK"
    update_status "shutdown" "Watchdog shut down" 0
}

# ==============================================================================
# STATUS DISPLAY
# ==============================================================================

# Get status
show_status() {
    echo -e "${BLUE}=== Orchestrator Watchdog Status (v3.0) ===${NC}"
    echo
    
    # Watchdog status
    if [[ -f "$WATCHDOG_PIDFILE" ]] && ps -p $(cat "$WATCHDOG_PIDFILE" 2>/dev/null) > /dev/null 2>&1; then
        echo -e "Watchdog: ${GREEN}Running${NC} (PID: $(cat "$WATCHDOG_PIDFILE"))"
    else
        echo -e "Watchdog: ${RED}Not running${NC}"
    fi
    
    # Orchestrator status
    if is_orchestrator_running; then
        echo -e "Orchestrator: ${GREEN}Running${NC} (PID: $(cat "$PIDFILE"))"
    else
        echo -e "Orchestrator: ${RED}Not running${NC}"
    fi
    
    # Configuration status
    if [[ -f "$CONFIG_FILE" ]]; then
        echo -e "Config: ${GREEN}Loaded${NC} ($CONFIG_FILE)"
    else
        echo -e "Config: ${YELLOW}Using defaults${NC} (run '$0 init-config' to create)"
    fi
    
    # Model
    echo -e "Model: ${CYAN}$MODEL${NC}"
    
    # Token usage
    if [[ -f "$TOKEN_TRACKING_FILE" ]]; then
        local tokens
        tokens=$(jq -r '.total_tokens // 0' "$TOKEN_TRACKING_FILE" 2>/dev/null || echo "0")
        local limit_pct=0
        if [[ $TOKEN_LIMIT_TOTAL -gt 0 ]]; then
            limit_pct=$((tokens * 100 / TOKEN_LIMIT_TOTAL))
        fi
        echo -e "Token Usage: ${tokens}/${TOKEN_LIMIT_TOTAL} (${limit_pct}%)"
    fi
    
    # Restart count
    local restarts
    restarts=$(get_restart_count)
    echo -e "Restarts (this hour): ${restarts}/${MAX_RESTARTS}"
    
    # Status file
    if [[ -f "$STATUS_FILE" ]]; then
        echo
        echo "Status file:"
        jq '.' "$STATUS_FILE"
    fi
    
    # Recent log entries
    if [[ -f "$LOGFILE" ]]; then
        echo
        echo "Recent log entries:"
        tail -5 "$LOGFILE" 2>/dev/null || true
    fi
}

# Show current configuration
show_config() {
    echo -e "${BLUE}=== Watchdog Configuration ===${NC}"
    echo
    
    if [[ -f "$CONFIG_FILE" ]]; then
        echo -e "Config file: ${GREEN}$CONFIG_FILE${NC}"
        echo
        cat "$CONFIG_FILE"
    else
        echo -e "Config file: ${YELLOW}Not found (using defaults)${NC}"
        echo
        echo "Current settings:"
        echo "  CHECK_INTERVAL=$CHECK_INTERVAL"
        echo "  MAX_RESTARTS=$MAX_RESTARTS"
        echo "  TOKEN_LIMIT_ENABLED=$TOKEN_LIMIT_ENABLED"
        echo "  TOKEN_LIMIT_TOTAL=$TOKEN_LIMIT_TOTAL"
        echo "  MODEL=$MODEL"
        echo "  SESSION_TIMEOUT=$SESSION_TIMEOUT"
        echo "  MEMORY_LIMIT_MB=$MEMORY_LIMIT_MB"
        echo "  LOG_ROTATION_ENABLED=$LOG_ROTATION_ENABLED"
        echo
        echo "Run '$0 init-config' to create a config file"
    fi
}

# ==============================================================================
# SIGNAL HANDLING
# ==============================================================================

# Handle signals
cleanup() {
    log "Received shutdown signal" "WARN"
    stop_watchdog
    exit 0
}

trap cleanup SIGINT SIGTERM

# ==============================================================================
# MAIN WATCHDOG LOOP
# ==============================================================================

run_watchdog() {
    # Check if already running
    if [[ -f "$WATCHDOG_PIDFILE" ]]; then
        local existing_pid=$(cat "$WATCHDOG_PIDFILE")
        if ps -p "$existing_pid" > /dev/null 2>&1; then
            log "Watchdog already running with PID: $existing_pid" "WARN"
            exit 1
        fi
    fi
    
    # Save our PID
    echo $$ > "$WATCHDOG_PIDFILE"
    
    log "=========================================" 
    log "Orchestrator Watchdog v3.0 started"
    log "Check interval: ${CHECK_INTERVAL}s"
    log "Max restarts/hour: $MAX_RESTARTS"
    log "Token limit: $TOKEN_LIMIT_TOTAL"
    log "Model: $MODEL"
    log "Watchdog PID: $$"
    log "========================================="
    
    # Initial start if not running
    if ! is_orchestrator_running; then
        start_orchestrator
    else
        local pid=$(cat "$PIDFILE" 2>/dev/null)
        log "Orchestrator already running (PID: $pid)" "OK"
        update_status "running" "Orchestrator already running" $pid
        record_session_start
    fi
    
    # Counters for periodic checks
    local token_check_counter=0
    local memory_check_counter=0
    
    # Main loop
    while true; do
        sleep $CHECK_INTERVAL
        
        # Increment counters
        token_check_counter=$((token_check_counter + CHECK_INTERVAL))
        memory_check_counter=$((memory_check_counter + CHECK_INTERVAL))
        
        # Check for rate limits before checking/restarting orchestrator
        # This prevents rapid restart loops during API rate limiting
        if ! check_rate_limit_status; then
            log "Rate limit detected during health check - waiting for cooldown" "WARN"
            # Stop current orchestrator if running (it's probably stuck in retry loop)
            if is_orchestrator_running; then
                log "Stopping orchestrator stuck in rate limit retry loop" "WARN"
                stop_orchestrator
            fi
            wait_for_rate_limit
            start_orchestrator || true
            token_check_counter=0
            memory_check_counter=0
            continue
        fi
        
        # Check if orchestrator is running
        if ! is_orchestrator_running; then
            log "Orchestrator not running - restarting..." "WARN"
            start_orchestrator || true
            token_check_counter=0
            memory_check_counter=0
            continue
        fi
        
        # Periodic token limit check
        if [[ $token_check_counter -ge $TOKEN_CHECK_INTERVAL ]]; then
            token_check_counter=0
            if ! check_token_limits; then
                log "Restarting due to token limit" "WARN"
                stop_orchestrator
                start_orchestrator || true
                continue
            fi
        fi
        
        # Periodic memory check
        if [[ $memory_check_counter -ge $MEMORY_CHECK_INTERVAL ]]; then
            memory_check_counter=0
            if ! check_memory_usage; then
                log "Restarting due to memory limit" "WARN"
                stop_orchestrator
                start_orchestrator || true
                continue
            fi
        fi
        
        # Session timeout check
        if ! check_session_timeout; then
            log "Restarting due to session timeout" "WARN"
            stop_orchestrator
            start_orchestrator || true
            continue
        fi
        
        # Update status to show we're monitoring
        local pid=$(cat "$PIDFILE" 2>/dev/null || echo 0)
        update_status "running" "Monitoring active" $pid
    done
}

# ==============================================================================
# COMMAND PARSING
# ==============================================================================

# Parse command
case "${1:-run}" in
    start)
        # Start in background
        log "Starting watchdog in background..."
        nohup "$0" run >> "$LOGFILE" 2>&1 &
        echo "Watchdog started in background (PID: $!)"
        ;;
    stop)
        if [[ -f "$WATCHDOG_PIDFILE" ]]; then
            kill $(cat "$WATCHDOG_PIDFILE") 2>/dev/null || true
            stop_orchestrator
            rm -f "$WATCHDOG_PIDFILE"
            echo "Watchdog stopped"
        else
            echo "Watchdog not running"
        fi
        ;;
    restart)
        stop_orchestrator
        start_orchestrator
        ;;
    status)
        show_status
        ;;
    config)
        show_config
        ;;
    init-config)
        generate_config
        ;;
    run|"")
        run_watchdog
        ;;
    *)
        echo "Orchestrator Watchdog v3.0"
        echo
        echo "Usage: $0 {start|stop|restart|status|config|init-config|run}"
        echo
        echo "Commands:"
        echo "  start       - Start watchdog in background"
        echo "  stop        - Stop watchdog and orchestrator"
        echo "  restart     - Restart the orchestrator"
        echo "  status      - Show current status"
        echo "  config      - Show current configuration"
        echo "  init-config - Generate default config file"
        echo "  run         - Run watchdog in foreground (default)"
        exit 1
        ;;
esac
